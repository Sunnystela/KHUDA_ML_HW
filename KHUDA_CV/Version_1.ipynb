{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Library**"
      ],
      "metadata": {
        "id": "ORmjcHlT-Qgm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ReeHrtxm-LYC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import time\n",
        "import random\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Model**"
      ],
      "metadata": {
        "id": "ajdGNW55-WUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# **1) Model define**\n",
        "### trans_VGG에서 사용할 함수인 conv_2 define\n",
        "\"\"\"\n",
        "\n",
        "def conv_2(in_dim, out_dim):\n",
        "    model = nn.Sequential(\n",
        "        nn.Conv2d(in_dim, out_dim, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),# Model define\n",
        "        nn.Conv2d(out_dim, out_dim, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def conv_3(in_dim, out_dim):\n",
        "    model = nn.Sequential(\n",
        "        nn.Conv2d(in_dim, out_dim, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),# Model define\n",
        "        nn.Conv2d(out_dim, out_dim, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_dim, out_dim, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_dim, out_dim, kernel_size = 3, padding = 1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2,2)\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "YnrVUVGl-ZGr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "레이어를 순차적으로 쌓아 모델을 정의한다.\n",
        "\n",
        "conv_2는 2개의 컨볼루션 레이어와 1개의 맥스 풀링 레이어로 되어 있고 conv_3는 4개의 컨볼로션 레이어와 1개의 맥스 풀링 레이어로 구성되어 있다."
      ],
      "metadata": {
        "id": "I9uNkRShiOMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define trans_VGG class**"
      ],
      "metadata": {
        "id": "DtjKQ3Ss-eOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class trans_VGG(nn.Module):\n",
        "    def __init__(self, base_dim):\n",
        "        super(trans_VGG, self).__init__()\n",
        "        self.feature = nn.Sequential(\n",
        "            conv_2(3, base_dim),\n",
        "            conv_2(base_dim, base_dim*2),\n",
        "            conv_2(base_dim*2, base_dim*4),\n",
        "            conv_3(base_dim*4, base_dim*8),\n",
        "            conv_3(base_dim*8, base_dim*8)\n",
        "        )\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(base_dim*8*7*7, base_dim*4*7*7),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(base_dim*4*7*7, base_dim*2*7*7),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(base_dim*2*7*7, base_dim*7*7)\n",
        "        )\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "3Ty-Lx7--jv0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###초기화\n",
        "train_VGG 클래스를 정의한다.\n",
        "\n",
        "self.feature: 여러개의 컨볼루션 레이어를 포함하는 부분\n",
        "self.fc_layer: 완전 연결 레이어 부분\n",
        "\n",
        "### forward\n",
        "x=self.feature(x) 입력 데이터를 self.feature 부분을 통해 처리한다.\n",
        "x=x.view(x,size(0), -1): 데이터를 1차월으로 변환\n",
        "x=self.fc_layer(x): 변환된 데이터를 self.fc_layer 부분을 통해 처리한다\n"
      ],
      "metadata": {
        "id": "oiVgwcsJjeUy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Hyper_paremeter : Learning rate, momentum, weight decay 등은 논문의 Hyper peremeter value로 초기화\n"
      ],
      "metadata": {
        "id": "0JlwvIx9-oB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "seed = time.time()\n",
        "\n",
        "def custom_init_weights(m):\n",
        "  if seed is not None:\n",
        "    torch.manual_seed(seed)\n",
        "  if isinstance(m, torch.nn.Linear) and m.weight is not None:\n",
        "    init.normal_(m.weight, mean=1, std=0.01)\n",
        "    if m.bias is not None:\n",
        "      init.constant_(m.bias, 0)\n",
        "\n",
        "model = trans_VGG(base_dim=64)\n",
        "\n",
        "loss = nn.BCELoss()\n",
        "optimizer =torch.optim.SGD(model.parameters(), lr = 0.01,momentum = 0.9, weight_decay = 0.0005)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', patience=10, factor=0.1, verbose=True)\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.RandomCrop(224)])\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uOjBQ4qCnC3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "모델의 가중치와 편향을 초기화한다. seed를 통해 랜덤 시드를 설정한다.\n",
        "\n",
        "\n",
        "ReducelROnPlateau 스케쥴러를 사용해 학습률을 조정한다.\n",
        "\n",
        "이미지를 텐서로 변환하고 랜덤으로 224x224로 자른다."
      ],
      "metadata": {
        "id": "ZrQRiRCJks0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Dataset**"
      ],
      "metadata": {
        "id": "iDUjpjGy-wJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Project 3 폴더 경로\n",
        "project_folder = '/content/drive/MyDrive/Project3'\n",
        "\n",
        "image = []\n",
        "label = []\n",
        "\n",
        "# Project 3 폴더 내부의 세부 폴더를 확인하고 이미지와 라벨 데이터 생성\n",
        "for subdir, _, files in os.walk(project_folder):\n",
        "    for file in files:\n",
        "        # 이미지 파일인지 확인\n",
        "        if file.endswith(('png', 'jpg', 'jpeg')):\n",
        "            image_path = os.path.join(subdir, file)\n",
        "            image.append(image_path)\n",
        "\n",
        "            # 이미지가 속한 세부 폴더의 이름을 라벨로 사용\n",
        "            label_name = os.path.basename(subdir)\n",
        "            label.append(label_name)\n",
        "\n",
        "indices = np.random.permutation(len(image))\n",
        "IMAGE = [image[i] for i in indices]\n",
        "LABEL = [label[i] for i in indices]\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image = transforms.RandomCrop(224)(image)\n",
        "        image = transforms.ToTensor()(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "TRAINING_image = []\n",
        "TRAINING_label = []\n",
        "TEST_image = []\n",
        "TEST_label = []\n",
        "\n",
        "for i in range(0,80):\n",
        "  for j in range(0,20):\n",
        "    for k in range(0,2):\n",
        "      TRAINING_image.append(image[200*j+i+k])\n",
        "      TRAINING_label.append(label[200*j+i+k])\n",
        "\n",
        "for i in range(80,100):\n",
        "  for j in range(0,20):\n",
        "    for k in range(0,2):\n",
        "      TEST_image.append(image[200*j+i+k])\n",
        "      TEST_label.append(label[200*j+i+k])\n",
        "\n",
        "train_dataset = CustomDataset(TRAINING_image, TRAINING_label, transform = transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE,num_workers=2)\n",
        "test_dataset = CustomDataset(TEST_image, TEST_label, transform = transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE,num_workers=2)"
      ],
      "metadata": {
        "id": "l7NWSJZD-yoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "61PMWGKo-2dQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# **3) TRAINING**\"\"\"\n",
        "\n",
        "EPOCH = 80\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "start_time = time.time()\n",
        "train_acc_lst, test_acc_lst = [],[]\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "  model.train()\n",
        "  correct_pred, num_examples = 0, 3200\n",
        "  for i, (_image1, _label1) in enumerate(train_loader):\n",
        "    image1 = _image1.to(DEVICE)\n",
        "    label1 = _label1[0]\n",
        "    vector1_tensor = model(image1)\n",
        "\n",
        "    if (i == 0): #Exception Case\n",
        "      image2 = image1\n",
        "      label2 = label1\n",
        "      vector2_tensor = vector1_tensor\n",
        "\n",
        "    similarity =  F.cosine_similarity(vector1_tensor, vector2_tensor, dim= -1)\n",
        "    scaled_similarity = torch.sigmoid(similarity)\n",
        "\n",
        "    if label1 == label2 and scaled_similarity.item() > 0.5:\n",
        "        correct_pred += 1\n",
        "    elif label1 != label2 and scaled_similarity.item() < 0.5:\n",
        "        correct_pred += 1\n",
        "\n",
        "    if label1 == label2:\n",
        "      target_vector = [1]\n",
        "    else :\n",
        "      target_vector = [0]\n",
        "\n",
        "    target_tensor = torch.tensor(target_vector).float()\n",
        "    target_tensor = target_tensor.to(DEVICE)\n",
        "    optimizer.zero_grad()\n",
        "    cost = loss(scaled_similarity, target_tensor)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if not i % 40:\n",
        "      print (f'Epoch: {epoch:03d}/{EPOCH:03d} | '\n",
        "            f'Batch {i:03d}/{len(train_loader):03d} |'\n",
        "             f' Cost: {cost:.4f}')\n",
        "\n",
        "    #연산량 감소를 위한 텐서 재활용\n",
        "    image2 = image1.clone()\n",
        "    label2 = label1\n",
        "    vector2_tensor = vector1_tensor.detach().clone()\n",
        "\n",
        "elapsed = (time.time() - start_time)/60\n",
        "print(f'Total Training Time: {elapsed:.2f} min')"
      ],
      "metadata": {
        "id": "rBiV7BHk-4MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "80 에포크만큼 학습을 진행한다.\n",
        "\n",
        "학습 정확도와 테스트 정확도를 저장할 리스트를 초기화한다.\n",
        "\n",
        "cosine 유사도를 계산하고 시그모이드 함수를 적용하여 유사도를 스케일링 한다.\n",
        "\n",
        "손실함수를 계산하고 역전파를 통해 가중치를 업데이트 한다.\n",
        "\n",
        "40번째 배치마다 진행 상황을 출력하고 텐서를 재활용하여 연산량을 줄인다.\n",
        "\n"
      ],
      "metadata": {
        "id": "F2BcWcWil11t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ktkY-078nXb6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}